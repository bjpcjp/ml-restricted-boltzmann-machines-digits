{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted Boltzmann Machine features for digit classification\n",
    "### From [sklearn](http://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html#sphx-glr-auto-examples-neural-networks-plot-rbm-logistic-classification-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Greyscale image data: pixel values can be interpreted as degrees of blackness on a white background.\n",
    "\n",
    "* The Bernoulli Restricted Boltzmann machine model (BernoulliRBM) can perform effective non-linear feature extraction.\n",
    "\n",
    "* First, artificially generate more labeled data by perturbing the training data with linear shifts of 1 pixel in each direction.\n",
    "\n",
    "* This example builds a classification pipeline with \n",
    "    * a BernoulliRBM feature extractor and \n",
    "    * a LogisticRegression classifier. \n",
    "    \n",
    "* Model hyperparameters (learning rate, hidden layer size, regularization) were optimized by grid search (not shown due of runtime constraints.)\n",
    "\n",
    "* Logistic regression on raw pixel values is presented for comparison. The example shows that the features extracted by the BernoulliRBM help improve the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.ndimage import convolve\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nudge_dataset(X, Y):\n",
    "    \"\"\"\n",
    "    This produces a dataset 5 times bigger than the original one,\n",
    "    by moving the 8x8 images in X around by 1px to left, right, down, up\n",
    "    \"\"\"\n",
    "    direction_vectors = [\n",
    "        [[0, 1, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [1, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 1],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 1, 0]]]\n",
    "\n",
    "    shift = lambda x, w: convolve(x.reshape((8, 8)), mode='constant',\n",
    "                                  weights=w).ravel()\n",
    "    X = np.concatenate([X] +\n",
    "                       [np.apply_along_axis(shift, 1, X, vector)\n",
    "                        for vector in direction_vectors])\n",
    "    Y = np.concatenate([Y for _ in range(5)], axis=0)\n",
    "    return X, Y\n",
    "\n",
    "# Load Data\n",
    "digits = datasets.load_digits()\n",
    "X = np.asarray(digits.data, 'float32')\n",
    "X, Y = nudge_dataset(X, digits.target)\n",
    "X = (X - np.min(X, 0)) / (np.max(X, 0) + 0.0001)  # 0-1 scaling\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Models we will use\n",
    "logistic = linear_model.LogisticRegression()\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
    "\n",
    "classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -25.39, time = 0.22s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -23.77, time = 0.30s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -22.94, time = 0.30s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -21.91, time = 0.29s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -21.69, time = 0.29s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -21.06, time = 0.28s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -20.89, time = 0.28s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -20.64, time = 0.28s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -20.36, time = 0.31s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -20.09, time = 0.27s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -20.08, time = 0.27s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -19.82, time = 0.28s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -19.64, time = 0.28s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -19.61, time = 0.28s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -19.57, time = 0.33s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -19.41, time = 0.27s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -19.30, time = 0.28s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -19.25, time = 0.28s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -19.27, time = 0.28s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -19.01, time = 0.27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyper-parameters. These were set by cross-validation,\n",
    "# using a GridSearchCV. Here we are not performing cross-validation to\n",
    "# save time.\n",
    "rbm.learning_rate = 0.06\n",
    "rbm.n_iter = 20\n",
    "# More components tend to give better prediction performance, but larger\n",
    "# fitting time\n",
    "rbm.n_components = 100\n",
    "logistic.C = 6000.0\n",
    "\n",
    "# Training RBM-Logistic Pipeline\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Training Logistic regression\n",
    "logistic_classifier = linear_model.LogisticRegression(C=100.0)\n",
    "logistic_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic regression using RBM features:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       174\n",
      "          1       0.92      0.95      0.93       184\n",
      "          2       0.95      0.98      0.97       166\n",
      "          3       0.97      0.91      0.94       194\n",
      "          4       0.97      0.95      0.96       186\n",
      "          5       0.92      0.93      0.93       181\n",
      "          6       0.98      0.97      0.97       207\n",
      "          7       0.95      1.00      0.97       154\n",
      "          8       0.90      0.88      0.89       182\n",
      "          9       0.91      0.93      0.92       169\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1797\n",
      "\n",
      "\n",
      "Logistic regression using raw pixel features:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.94      0.89       174\n",
      "          1       0.57      0.55      0.56       184\n",
      "          2       0.72      0.85      0.78       166\n",
      "          3       0.76      0.74      0.75       194\n",
      "          4       0.85      0.82      0.84       186\n",
      "          5       0.74      0.75      0.75       181\n",
      "          6       0.93      0.88      0.91       207\n",
      "          7       0.86      0.90      0.88       154\n",
      "          8       0.68      0.55      0.61       182\n",
      "          9       0.71      0.74      0.72       169\n",
      "\n",
      "avg / total       0.77      0.77      0.77      1797\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(\n",
    "        Y_test,\n",
    "        classifier.predict(X_test))))\n",
    "\n",
    "print(\"Logistic regression using raw pixel features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(\n",
    "        Y_test,\n",
    "        logistic_classifier.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4.2, 4))\n",
    "for i, comp in enumerate(rbm.components_):\n",
    "    plt.subplot(10, 10, i + 1)\n",
    "    plt.imshow(comp.reshape((8, 8)), cmap=plt.cm.gray_r,\n",
    "               interpolation='nearest')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.suptitle('100 components extracted by RBM', fontsize=16)\n",
    "plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/home/bjpcjp/Downloads/figure_1.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
